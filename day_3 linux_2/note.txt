Linux Part 2

Content
1.	Process Management
2.	Memory Management
3.	Linux Commands - User Management, Group Management and File Permissions
4.	Linux Commands - Processes


Processes
A process is a program in execution.

Computer programs are written as text files. When they are executed, they run as processes to carry out the instructions specified in the written program.

Sections of a Process:
-	Stack: The process Stack contains the temporary data such as method/function parameters, return address and local variables.

-	Heap: This is the memory that is dynamically allocated to a process during its execution.

-	Text: This consists of the ongoing activity of a process that is represented by the value of the Program Counter and the contents of the processor's registers.

Data:The global as well as static variables are included in this section


Process Lifecycle
When a process is in execution on an operating system, it passes through a series of stages before it's completion (successful or otherwise).

The names of these stages can differ from one OS to another as they are not standardized but their importance remain the same.
 
-	Start: This is the initial state when a process is ftrst started/created.
-	Ready: A process is in ready state when waiting for a processor to be assigned to it either after Start state or when interrupted by a scheduler
-	Running: When a process has been assigned a processor by the scheduler and can now run its instructions
-	Waiting: If a process needs to wait for a resource,user input, data from a ftle; it is placed in waiting state
-	Terminated or Exited: When a process finishes its execution or is terminated by the OS, it is placed in this state where it waits to be removed from the main memory


PCB
A Process Control Block (PCB) is a data structure that is maintained for each process by an operating system. It contains important information about the process which is needed to keep track of the process and is identified by a Process ID (PIO)

•	Process State
•	Process Privileges
•	Process ID
•	Pointer
•	Process Counter
•	CPU Registers
•	CPU Scheduling Information
•	Memory Management Information
•	Accounting Information
•	10 Status Information

•	Process State: The current state of the process i.e.. whether it is ready, running, waiting, or whatever.
•	Process Privileges: This is required to allow/disallow access to system resources.
•	Process ID: Unique identification for each of the process in the operating system.
•	Pointer: A pointer to parent process.
•	Process Counter: Program Counter is a pointer to the address of the next instruction to be executed for this process.
•	CPU Registers: Various CPU registers where process need to be stored for execution for running state.
•	CPUScheduling Information: Process prionty and other scheduling information which 1s required to schedule the process.
•	Memory Management Information: This includes the information of page table, memory limits, Segment table depending on memory used by the operating system.
•	Accounting Information: This includes the amount of CPU used for process execution, time limits, execution ID etc.
•	10 Status Information: This includes a list of 1/0 devices allocated to the process.


Memory Management
An operating system performs Memory Management by handling or managing primary memory and moving processes back and forth between main memory and disk during execution.
Memory management keeps track of each memory location, whether it is allocated to some process or if it is free. It checks how much memory is to be allocated to processes and decides which process will get memory at what time.
It tracks whenever some memory gets freed or unallocated and it updates the status accordingly
In most computers, the Operating System resides in a part of memory, and the rest is used by multiple processes. The task of subdividing the memory among different processes is called Memory Management


Importance of Memory Management
•	Why Memory Management is Required?
•	Allocate and Deallocate memory before and after process execution.
•	To keep track of used memory space by processes.
•	To minimize fragmentation issues.
•	To proper utilization of main memory.
•	To maintain data integrity while executing of process.


Logical Address
A logical address, also known as a virtual address, is an address generated by the CPU during program execution. It is the address seen by the process and is relative to the program's address space. 
The process accesses memory using logical addresses, which are translated by the operating system into physical addresses.
An address that is created by the CPU while a program is running is known as a logical address. Because the logical address is virtual-that is, it doesn't exist physically-it is also referred to as such. 
The CPU uses this address as a reference to go to the actual memory location. All logical addresses created from a program's perspective are referred to as being in the "logical address space".
This address is used as a reference to access the physical memory location by CPU.


Physical Address
A physical address is the actual address in the main memory where data is stored. 
It is a location in physical memory, as opposed to a virtual address. Physical addresses are used by the Memory Management Unit (MMU) to translate logical addresses into physical addresses. 
The user must use the corresponding logical address to go to the physical address rather than directly accessing the physical address. For a computer program to function, physical memory space is required. Therefore, 
the logical address and physical address need to be mapped before the program is run.


MMU 
The physical hardware of a computer that manages its virtual memory and caching functions is called the memory management unit (MMU). 
The MMU is typically found inside the central processing unit (CPU) of the computer. The MMU receives all inputs for data requests and decides whether to retrieve the data from physical main memory


Static and Dynamic Loading
•	Static Loading: Static Loading is basically loading the entire program into a fixed address. It requires more memory space.
•	Dynamic Loading: The entire program and all data of a process must be in physical memory for the process to execute. 
So, the size of a process is limited to the size of physical memory. To gain proper memory utilization. dynamic loading is used. In dynamic loading, 
a routine is not loaded until it is called. All routines are residing on disk in a relocatable load format One of the advantages of dynamic loading is that the unused routine is never loaded. 
This loading is useful when a large amount of code is needed to handle it efficiently.


Static and Dynamic Linking
A linker is a program that takes one or more object files generated by a compiler and combines them into a single executable file
•	Static Linking: In static linking,the linker combines all necessary program modules into asingle executable program.So there is no runtime dependency. Some operating systems support only static linking, in which system language libraries are treated like any other object module.
•	Dynamic Linking: The basic concept of dynamic linking is similar to dynamic loading. In dynamic linking, "Stub" is included for each appropriate library routine reference. A stub is a small piece of code. When the stub is executed, it checks whether the needed routine is already in memory or not. If not available then the program loads the routine into memory.


Swapping

When a process is executed it must have resided in memory. 
Swapping is a process of swapping a process temporarily into a secondary memory from the main memory, 
which is fast compared to secondary memory. A swapping allows more processes to be run and can be fit into memory at one time

Swapping is also known as roll-out, or roll because if a higher priority process arrives and wants service. 
the memory manager can swap out the lower priority process and then load and execute the higher priority process. 
After finishing higher priority work, the lower priority process swapped back in memory and continued to the execution process.


Memory Allocation
Contiguous Memory Allocation: Contiguous memory allocation is basically a method in which a single contiguous section/part of memory is allocated to a process or file needing it. 
Because of this all the available memory space resides at the same place together, which means that the freely/unused available memory partitions are not distributed in a random fashion here and there across the whole memory space.

Non-Contiguous Memory Allocation: Non-Contiguous memory allocation is basically a method on the contrary to contiguous allocation method, allocates the memory space present in different locations to the process as per it's requirements. 
As all the available memory space is in a distributed pattern so the freely available memory space is also scattered here and there. This technique of memory allocation helps to reduce the wastage of memory. which eventually gives rise to Internal and external fragmentation.


Fragmentat•10n
When a process is loaded and removed after execution from memory, it creates a small free hole. These holes can not be assigned to new processes because the holes are not combined or do not fulfill thememory requirement of the process. Thai problem is known as Fragmentation.
To achieve a degree of multiprogramming, we must reduce the waste of memory or fragmentation problems
Internal fragmentation: Internal fragmentation occurs when memory blocks are allocated to the process more than their requested size. Due to this some unused space is left over and creating an internal fragmentation problem
External fragmentation: In External Fragmentation, we have a free memory block, but we can not assign it to a process because blocks are not contiguous


Paging
Paging is a memory management scheme that eliminates the need for a contiguous allocation of physical memory. The process of retrieving processes in the form of pages from the secondary storage into the main memory is known as paging. 
The basic purpose of paging is to separate each procedure into pages. Additionally, frames will be used to split the main memory. This scheme permits the physical address space of a process to be non - contiguous

This is where the concept of Logical Memory (Virtual Memory), Physical Memory and MMU

The mapping from virtual to physical address is done by the memory management unit (MMU) which is a hardware device that implements the paging technique


Linux Commands - User Management and Permissions

Linux is a multi-user operating system and as such it is important to manage the level of privileges of each user and prevent them from accessing the confidential files of other users.

A user is an entity, in a Linux operating system, that can manipulate files and perform several other operations. Each user is assigned an ID that isunique for each user in the operating system.

A user in Linux is associated with a user account, which consists of several properties defining their identity and privileges within thesystem. These properties are a username, UID (User ID), GID (Group ID), home directory, default shell, and password.

A group is a collection of related users.


user Management
 
1.	List all users: $ cat /etc/passwd
2.	See User Ids:$ id <username>
3.	Create User:$ sudo useradd --create-home <new user>
4.	Add/Change User Password:$ sudo passwd <new_user>
5.	View User: $ id <user>
6.	Modify User:$ usermod <user>
7.	Change User Group:$ sudo usermod -g <groupname> <username>
8.	Change User ID: $ sudo usermod -u <new id> user
9.	Delete User:$ sudo userdel -r <user>
10.	Adding User to Group:$ sudo gpasswd -a <user> <groupname>
11.	Deleting a User from a Group:$ udo gpasswd -d <user> <groupname>
12.	Change User Password:$ sudo passwd <user>


Group Management
1.	Create New Group:$ sudo groupadd <new_group>
2.	View Group:$ cat /etc/group I grep <group>
3.	Modify Group:$ groupmod <group>
4.	Change Group ID:$ sudo groupmod -g <new id> <group>
5.	Change Group Name:$ sudo groupmod -n <new_name> <group>
6.	Delete Group:$ sudo groupdel <group>
7.	Add Users to a Group:$ sudo usermod -aG <group> <user>


File Permission
Permission Groups in Linux:
•	Owners: These permissions apply exclusively to the individuals who own the files or directories
•	Groups: Permissions can be assigned to a specific group of users, impacting only those within that particular group.
•	All Users: These permissions apply universally to all users on the system, presenting the highest security risk. Assigning permissions to all users should be done cautiously to prevent potential security vulnerabilities.

File Permissions in Linux:
•	r: Read the file's content
•	w: Write to or Modify the file's content
•	x: Execute the file

File Permission Symbols:
•	+• Add permission
•	-: Remove permission
•	=: Set permission to a specific value

User:
•	u (User): The user permissions apply only to the owner of the file or directory, they will notimpact the actions of other users.
•	g (Group): The group permissions apply only to the group that has been assigned to the file or directory, they will not affect the actions of other users.
•	o (Others): The other permissions apply to all other users on the system, this is the permission group that youwant to watch the most. It poses high security risk if uses carelessly.
 
•	a (All Three Groups): Permission applies to all three (user, group, others)
